{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "REQUIREMENTS \n\nThe purpose of this assignment is to learn how feature engineering boosts model performance. You will apply Discrete Fourier Transformation on the accelerometer sensor time series, transforming the dataset from time to frequency domain. \n\nAfter that, you\u2019ll use a classification algorithm of your choice to classify sensor data in multiple categories: brushing teeth, climbing stairs.\n\nREFERENCE   \nhttps://en.wikipedia.org/wiki/Discrete_Fourier_transform   \nhttps://spark.apache.org/docs/3.1.1/ml-classification-regression.html#gradient-boosted-trees-gbts \n\nThis notebook is designed to run in a IBM Watson Studio default runtime (NOT the Watson Studio Apache Spark Runtime as the default runtime with 1 vCPU is free of charge). Therefore, we install Apache Spark in local mode for test purposes only. Don't use it in production.\n\nIf running outside Watson Studio, this should work as well. In case you are running in an Apache Spark context outside Watson Studio, remove the Apache Spark setup in the first notebook cells.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n\n\nif ('sc' in locals() or 'sc' in globals()):\n    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n    \n",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install pyspark==2.4.5",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting pyspark==2.4.5\n  Downloading pyspark-2.4.5.tar.gz (217.8 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 217.8 MB 9.6 kB/s  eta 0:00:01\ufffd\ufffd\u2588\u258e            | 131.0 MB 56.0 MB/s eta 0:00:02     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 148.2 MB 56.0 MB/s eta 0:00:02\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 162.7 MB 56.0 MB/s eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.7\n  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 197 kB 50.4 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=834cc163a5784b65ad4534f052d8e0a034ea9cef7d68fa69c6c1e46233608ac8\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/01/c0/03/1c241c9c482b647d4d99412a98a5c7f87472728ad41ae55e1e\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.4.5\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "!pip install https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true\n  Downloading https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true (9.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.9 MB 14.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from systemml==1.3.0) (1.18.5)\nRequirement already satisfied: scipy>=0.15.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from systemml==1.3.0) (1.5.0)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from systemml==1.3.0) (1.0.5)\nRequirement already satisfied: scikit-learn in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from systemml==1.3.0) (0.23.1)\nRequirement already satisfied: Pillow>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from systemml==1.3.0) (7.2.0)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas->systemml==1.3.0) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas->systemml==1.3.0) (2020.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn->systemml==1.3.0) (2.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn->systemml==1.3.0) (0.16.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->systemml==1.3.0) (1.15.0)\nBuilding wheels for collected packages: systemml\n  Building wheel for systemml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for systemml: filename=systemml-1.3.0-py3-none-any.whl size=9882972 sha256=4a81a27a113cbc0e25a53b9fa9e68614d9bfdedd3b0a2a0a9d6bb4ba519e8b4e\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/ed/96/15/1042ed0087d53c21a17788d99d5581169482cfe683f1f6e60a\nSuccessfully built systemml\nInstalling collected packages: systemml\nSuccessfully installed systemml-1.3.0\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SQLContext, SparkSession\nfrom pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\nfrom pyspark.sql import SparkSession\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\nSo the first thing we need to ensure is that we are on version 1.3.0 or higher of SystemML. Use the code block below to check the version. \nNote: SystemML 1.3 contains an important and necessary fix.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!mkdir -p /tmp/wsuser/systemml",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from systemml import MLContext, dml\nml = MLContext(spark)\nml.setConfigProperty(\"sysml.localtmpdir\", \"mkdir /tmp/wsuser/systemml\")\nprint(ml.version())\n    \nif not ml.version() == '1.3.0-SNAPSHOT':\n    raise ValueError('please upgrade to SystemML 1.3.0, or restart your Kernel (Kernel->Restart & Clear Output)')",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "1.3.0-SNAPSHOT\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget https://github.com/IBM/coursera/blob/master/coursera_ml/shake.parquet?raw=true\n!mv shake.parquet?raw=true shake.parquet",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2021-03-18 15:55:38--  https://github.com/IBM/coursera/blob/master/coursera_ml/shake.parquet?raw=true\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://github.com/IBM/skillsnetwork/blob/master/coursera_ml/shake.parquet?raw=true [following]\n--2021-03-18 15:55:39--  https://github.com/IBM/skillsnetwork/blob/master/coursera_ml/shake.parquet?raw=true\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github.com/IBM/skillsnetwork/raw/master/coursera_ml/shake.parquet [following]\n--2021-03-18 15:55:39--  https://github.com/IBM/skillsnetwork/raw/master/coursera_ml/shake.parquet\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/IBM/skillsnetwork/master/coursera_ml/shake.parquet [following]\n--2021-03-18 15:55:39--  https://raw.githubusercontent.com/IBM/skillsnetwork/master/coursera_ml/shake.parquet\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 74727 (73K) [application/octet-stream]\nSaving to: \u2018shake.parquet?raw=true\u2019\n\nshake.parquet?raw=t 100%[===================>]  72.98K  --.-KB/s    in 0.002s  \n\n2021-03-18 15:55:39 (45.1 MB/s) - \u2018shake.parquet?raw=true\u2019 saved [74727/74727]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now it\u2019s time to read the sensor data and create a temporary query table."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df=spark.read.parquet('shake.parquet')",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.show()",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----+---------+-----+-----+-----+\n|CLASS| SENSORID|    X|    Y|    Z|\n+-----+---------+-----+-----+-----+\n|    2| qqqqqqqq| 0.12| 0.12| 0.12|\n|    2|aUniqueID| 0.03| 0.03| 0.03|\n|    2| qqqqqqqq|-3.84|-3.84|-3.84|\n|    2| 12345678| -0.1| -0.1| -0.1|\n|    2| 12345678|-0.15|-0.15|-0.15|\n|    2| 12345678| 0.47| 0.47| 0.47|\n|    2| 12345678|-0.06|-0.06|-0.06|\n|    2| 12345678|-0.09|-0.09|-0.09|\n|    2| 12345678| 0.21| 0.21| 0.21|\n|    2| 12345678|-0.08|-0.08|-0.08|\n|    2| 12345678| 0.44| 0.44| 0.44|\n|    2|    gholi| 0.76| 0.76| 0.76|\n|    2|    gholi| 1.62| 1.62| 1.62|\n|    2|    gholi| 5.81| 5.81| 5.81|\n|    2| bcbcbcbc| 0.58| 0.58| 0.58|\n|    2| bcbcbcbc|-8.24|-8.24|-8.24|\n|    2| bcbcbcbc|-0.45|-0.45|-0.45|\n|    2| bcbcbcbc| 1.03| 1.03| 1.03|\n|    2|aUniqueID|-0.05|-0.05|-0.05|\n|    2| qqqqqqqq|-0.44|-0.44|-0.44|\n+-----+---------+-----+-----+-----+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install pixiedust",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting pixiedust\n  Downloading pixiedust-1.1.19.tar.gz (197 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 197 kB 18.8 MB/s eta 0:00:01\n\u001b[?25hCollecting geojson\n  Downloading geojson-2.5.0-py2.py3-none-any.whl (14 kB)\nCollecting astunparse\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: markdown in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pixiedust) (3.1.1)\nCollecting colour\n  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pixiedust) (2.24.0)\nRequirement already satisfied: matplotlib in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pixiedust) (3.2.2)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pixiedust) (1.0.5)\nRequirement already satisfied: six<2.0,>=1.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from astunparse->pixiedust) (1.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from astunparse->pixiedust) (0.34.2)\nRequirement already satisfied: setuptools>=36 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from markdown->pixiedust) (47.3.1.post20200622)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->pixiedust) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->pixiedust) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->pixiedust) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->pixiedust) (2.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->pixiedust) (1.2.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->pixiedust) (2.8.1)\nRequirement already satisfied: numpy>=1.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->pixiedust) (1.18.5)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->pixiedust) (0.10.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->pixiedust) (2.4.7)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas->pixiedust) (2020.1)\nBuilding wheels for collected packages: pixiedust\n  Building wheel for pixiedust (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pixiedust: filename=pixiedust-1.1.19-py3-none-any.whl size=321803 sha256=4d3ba45c4607bdbb94444dc31b45c427d3bf7febb2bd0cfd856b014082f724cb\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/05/07/e7/8aca0e820027a63157a916424fd748fb2a2a3e71de5e08eeb8\nSuccessfully built pixiedust\nInstalling collected packages: geojson, astunparse, colour, pixiedust\nSuccessfully installed astunparse-1.6.3 colour-0.1.5 geojson-2.5.0 pixiedust-1.1.19\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "tableView"
                    }
                }
            },
            "cell_type": "code",
            "source": "# REFERENCE: https://pixiedust.github.io/pixiedust/\n\nimport pixiedust\ndisplay(df)",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Pixiedust database opened successfully\nTable VERSION_TRACKER created successfully\nTable METRICS_TRACKER created successfully\n\nShare anonymous install statistics? (opt-out instructions)\n\nPixieDust will record metadata on its environment the next time the package is installed or updated. The data is anonymized and aggregated to help plan for future releases, and records only the following values:\n\n{\n   \"data_sent\": currentDate,\n   \"runtime\": \"python\",\n   \"application_version\": currentPixiedustVersion,\n   \"space_id\": nonIdentifyingUniqueId,\n   \"config\": {\n       \"repository_id\": \"https://github.com/ibm-watson-data-lab/pixiedust\",\n       \"target_runtimes\": [\"Data Science Experience\"],\n       \"event_id\": \"web\",\n       \"event_organizer\": \"dev-journeys\"\n   }\n}\nYou can opt out by calling pixiedust.optOut() in a new cell.\n",
                    "name": "stdout"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.19</span>\n        </div>\n        "
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "text": "\u001b[31mPixiedust runtime updated. Please restart kernel\u001b[0m\nTable SPARK_PACKAGES created successfully\nTable USER_PREFERENCES created successfully\nTable service_connections created successfully\n",
                    "name": "stdout"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "DataFrame[CLASS: bigint, SENSORID: string, X: double, Y: double, Z: double]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.createOrReplaceTempView(\"df\")",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We\u2019ll use Apache SystemML to implement Discrete Fourier Transformation. This way all computation continues to happen on the Apache Spark cluster for advanced scalability and performance."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Implementing Discrete Fourier Transformation in a linear algebra programming language is simple. Apache SystemML DML is such a language and as you can see the implementation is straightforward and doesn\u2019t differ too much from the mathematical definition (Just note that the sum operator has been swapped with a vector dot product using the %*% syntax borrowed from R\n):\n\n<img style=\"float: left;\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1af0a78dc50bbf118ab6bd4c4dcc3c4ff8502223\">\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dml_script = '''\nPI = 3.141592654\nN = nrow(signal)\n\nn = seq(0, N-1, 1)\nk = seq(0, N-1, 1)\n\nM = (n %*% t(k))*(2*PI/N)\n\nXa = cos(M) %*% signal\nXb = sin(M) %*% signal\n\nDFT = cbind(Xa, Xb)\n'''",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "GUIDELINES for a better understanding of the above lines:\n\ndml_script = '''\nPI = 3.141592654\nN = nrow(signal) // Number of rows in the signal vector. note: signal is the input vector for dml_script.\n\nn = seq(0, N-1, 1) // Generate vector n with numbers from 0 to N-1, incrementing step: 1\nk = seq(0, N-1, 1) // Generate vector k\n\nM = (n %*% t(k))*(2*PI/N) // Multiply vector n with the transpose of vector k. Multiply the result with a scalar. The output is a matrix M.\n\nXa = cos(M) %*% signal // cos(M) produces a matrix, which is multiplied with the signal vector. The output is a matrix Xa.\nXb = sin(M) %*% signal // sin(M) produces a matrix, which is multiplied with the signal vector. The output is a matrix Xb.\n\nDFT = cbind(Xa, Xb) // column-wise matrix concatenation: concatenates the second matrix as additional columns to the first matrix.\n'''\n\nREFERENCE: http://apache.github.io/systemds/site/dml-language-reference"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now it\u2019s time to create a function which takes a single row Apache Spark data frame as argument (the one containing the accelerometer measurement time series for one axis) and returns the Fourier transformation of it. In addition, we are adding an index column for later joining all axis together and renaming the columns to appropriate names. The result of this function is an Apache Spark DataFrame containing the Fourier Transformation of its input in two columns. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.sql.functions import monotonically_increasing_id\n\ndef dft_systemml(signal,name):\n    prog = dml(dml_script).input('signal', signal).output('DFT')\n    \n    return (\n\n    # execute the script inside the SystemML engine running on top of Apache Spark\n    ml.execute(prog) \n     \n         # read result from SystemML execution back as SystemML Matrix\n        .get('DFT') \n     \n         # convert SystemML Matrix to ApacheSpark DataFrame \n        .toDF() \n     \n         # rename default column names\n        .selectExpr('C1 as %sa' % (name), 'C2 as %sb' % (name)) \n     \n         # add unique ID per row for later joining\n        .withColumn(\"id\", monotonically_increasing_id())\n    )        ",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now it\u2019s time to create individual DataFrames containing only a subset of the data. For a given accelerometer, we filter each sensor axis for CLASS 1, then each sensor axis for CLASS 2. This means that we\u2019ll get 6 DataFrames. Implement this using the relational API of DataFrames or SparkSQL. Make sure that each DataFrame has only ONE column (only the measurement, without the CLASS column)."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nx0 = df.filter(df.CLASS==1).select('X') # a DataFrame containing only measurements of class 1 from the x axis\ny0 = df.filter(df.CLASS==1).select('Y') # a DataFrame containing only measurements of class 1 from the y axis\nz0 = df.filter(df.CLASS==1).select('Z') # a DataFrame containing only measurements of class 1 from the z axis\nx1 = ### YOUR CODE HERE ### a DataFrame containing only measurements of class 2 from the x axis\ny1 = ### YOUR CODE HERE ### a DataFrame containing only measurements of class 2 from the y axis\nz1 = ### YOUR CODE HERE ### a DataFrame containing only measurements of class 2 from the z axis\n\n# Use the following commands to check the content of df and newly created DataFrames:\n\ndf.show()\n\nx0.show()\ny0.show()\nz0.show()\nx1.show()\ny1.show()\nz1.show()",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----+---------+-----+-----+-----+\n|CLASS| SENSORID|    X|    Y|    Z|\n+-----+---------+-----+-----+-----+\n|    2| qqqqqqqq| 0.12| 0.12| 0.12|\n|    2|aUniqueID| 0.03| 0.03| 0.03|\n|    2| qqqqqqqq|-3.84|-3.84|-3.84|\n|    2| 12345678| -0.1| -0.1| -0.1|\n|    2| 12345678|-0.15|-0.15|-0.15|\n|    2| 12345678| 0.47| 0.47| 0.47|\n|    2| 12345678|-0.06|-0.06|-0.06|\n|    2| 12345678|-0.09|-0.09|-0.09|\n|    2| 12345678| 0.21| 0.21| 0.21|\n|    2| 12345678|-0.08|-0.08|-0.08|\n|    2| 12345678| 0.44| 0.44| 0.44|\n|    2|    gholi| 0.76| 0.76| 0.76|\n|    2|    gholi| 1.62| 1.62| 1.62|\n|    2|    gholi| 5.81| 5.81| 5.81|\n|    2| bcbcbcbc| 0.58| 0.58| 0.58|\n|    2| bcbcbcbc|-8.24|-8.24|-8.24|\n|    2| bcbcbcbc|-0.45|-0.45|-0.45|\n|    2| bcbcbcbc| 1.03| 1.03| 1.03|\n|    2|aUniqueID|-0.05|-0.05|-0.05|\n|    2| qqqqqqqq|-0.44|-0.44|-0.44|\n+-----+---------+-----+-----+-----+\nonly showing top 20 rows\n\n+-----+\n|    X|\n+-----+\n|  0.0|\n|  0.0|\n|  0.0|\n|  0.0|\n|  0.0|\n| 0.01|\n|-0.01|\n|-0.01|\n|  0.0|\n|-0.01|\n|-0.01|\n|  0.0|\n|  0.0|\n|-0.01|\n|  0.0|\n| 0.01|\n|-0.01|\n|-0.01|\n| 0.01|\n|  0.0|\n+-----+\nonly showing top 20 rows\n\n+-----+\n|    Y|\n+-----+\n|  0.0|\n|  0.0|\n|  0.0|\n|  0.0|\n|  0.0|\n| 0.01|\n|-0.01|\n|-0.01|\n|  0.0|\n|-0.01|\n|-0.01|\n|  0.0|\n|  0.0|\n|-0.01|\n|  0.0|\n| 0.01|\n|-0.01|\n|-0.01|\n| 0.01|\n|  0.0|\n+-----+\nonly showing top 20 rows\n\n+-----+\n|    Z|\n+-----+\n|  0.0|\n|  0.0|\n|  0.0|\n|  0.0|\n|  0.0|\n| 0.01|\n|-0.01|\n|-0.01|\n|  0.0|\n|-0.01|\n|-0.01|\n|  0.0|\n|  0.0|\n|-0.01|\n|  0.0|\n| 0.01|\n|-0.01|\n|-0.01|\n| 0.01|\n|  0.0|\n+-----+\nonly showing top 20 rows\n\n+-----+\n|    X|\n+-----+\n| 0.12|\n| 0.03|\n|-3.84|\n| -0.1|\n|-0.15|\n| 0.47|\n|-0.06|\n|-0.09|\n| 0.21|\n|-0.08|\n| 0.44|\n| 0.76|\n| 1.62|\n| 5.81|\n| 0.58|\n|-8.24|\n|-0.45|\n| 1.03|\n|-0.05|\n|-0.44|\n+-----+\nonly showing top 20 rows\n\n+-----+\n|    Y|\n+-----+\n| 0.12|\n| 0.03|\n|-3.84|\n| -0.1|\n|-0.15|\n| 0.47|\n|-0.06|\n|-0.09|\n| 0.21|\n|-0.08|\n| 0.44|\n| 0.76|\n| 1.62|\n| 5.81|\n| 0.58|\n|-8.24|\n|-0.45|\n| 1.03|\n|-0.05|\n|-0.44|\n+-----+\nonly showing top 20 rows\n\n+-----+\n|    Z|\n+-----+\n| 0.12|\n| 0.03|\n|-3.84|\n| -0.1|\n|-0.15|\n| 0.47|\n|-0.06|\n|-0.09|\n| 0.21|\n|-0.08|\n| 0.44|\n| 0.76|\n| 1.62|\n| 5.81|\n| 0.58|\n|-8.24|\n|-0.45|\n| 1.03|\n|-0.05|\n|-0.44|\n+-----+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Since we\u2019ve created the DFT function before, we can just call it for each of the 6 DataFrames. Since the result of this function call is also a DataFrame, we can use a pyspark best practice by calling methods on the DataFrame sequentially. So this is what we are going to do:\n\n- Call DFT for each class and accelerometer sensor axis.\n- Join the DataFrames on the ID column. \n- Re-add a column containing the class index.\n- Stack both Dataframes for each classes together.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.sql.functions import lit\n\ndf_class_0 = dft_systemml(x0,'x') \\\n    .join(dft_systemml(y0,'y'), on=['id'], how='inner') \\\n    .join(dft_systemml(z0,'z'), on=['id'], how='inner') \\\n    .withColumn('class', lit(0))\n    \ndf_class_1 = dft_systemml(x1,'x') \\\n    .join(dft_systemml(y1,'y'), on=['id'], how='inner') \\\n    .join(dft_systemml(z1,'z'), on=['id'], how='inner') \\\n    .withColumn('class', lit(1))\n\ndf_dft = df_class_0.union(df_class_1)\n\ndf_dft.show()",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.678 sec.\nNumber of executed Spark inst:\t0.\n\n\nSystemML Statistics:\nTotal execution time:\t\t0.259 sec.\nNumber of executed Spark inst:\t0.\n\n\nSystemML Statistics:\nTotal execution time:\t\t0.261 sec.\nNumber of executed Spark inst:\t0.\n\n\n[Stage 41:>                                                         (0 + 1) / 1]\n                                                                                \n[Stage 43:>                                                         (0 + 1) / 1]\nSystemML Statistics:\nTotal execution time:\t\t19.940 sec.\nNumber of executed Spark inst:\t6.\n\n                                                                                \n\n[Stage 49:>                                                         (0 + 1) / 1]\n                                                                                \n[Stage 51:>                                                         (0 + 1) / 1]\nSystemML Statistics:\nTotal execution time:\t\t17.989 sec.\nNumber of executed Spark inst:\t6.\n\n                                                                                \n\n[Stage 57:>                                                         (0 + 1) / 1]\n                                                                                \n[Stage 59:>                                                         (0 + 1) / 1]\nSystemML Statistics:\nTotal execution time:\t\t17.738 sec.\nNumber of executed Spark inst:\t6.\n\n                                                                                \n\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n| id|                  xa|                  xb|                  ya|                  yb|                  za|                  zb|class|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n| 26| 0.03912775214058598|-0.09049016952668232| 0.03912775214058598|-0.09049016952668232| 0.03912775214058598|-0.09049016952668232|    0|\n| 29|0.006260524476137005|-0.05765058448048809|0.006260524476137005|-0.05765058448048809|0.006260524476137005|-0.05765058448048809|    0|\n| 65| -0.0686442877106673| 0.06538926077517343| -0.0686442877106673| 0.06538926077517343| -0.0686442877106673| 0.06538926077517343|    0|\n| 19| 0.07207851982267682|-0.00555713532424...| 0.07207851982267682|-0.00555713532424...| 0.07207851982267682|-0.00555713532424...|    0|\n| 54| 0.03806782602909542|-0.15673003795074777| 0.03806782602909542|-0.15673003795074777| 0.03806782602909542|-0.15673003795074777|    0|\n|  0| 0.06178937294558884|-0.03961749197816182| 0.06178937294558884|-0.03961749197816182| 0.06178937294558884|-0.03961749197816182|    0|\n|112|0.050945537592681445|-0.00299428645504...|0.050945537592681445|-0.00299428645504...|0.050945537592681445|-0.00299428645504...|    0|\n|113| 0.06178937118785787| 0.03961749600785146| 0.06178937118785787| 0.03961749600785146| 0.06178937118785787| 0.03961749600785146|    0|\n| 22|-0.00942353499552...|0.014489276203582657|-0.00942353499552...|0.014489276203582657|-0.00942353499552...|0.014489276203582657|    0|\n|  7|-0.02139526027010...| 0.11560580654216471|-0.02139526027010...| 0.11560580654216471|-0.02139526027010...| 0.11560580654216471|    0|\n| 77|-0.07768949082949561|0.039133460895471164|-0.07768949082949561|0.039133460895471164|-0.07768949082949561|0.039133460895471164|    0|\n| 34|-0.08799817666162946|0.017746602649508163|-0.08799817666162946|0.017746602649508163|-0.08799817666162946|0.017746602649508163|    0|\n| 50| -0.0189063133643019|-0.08871621465767468| -0.0189063133643019|-0.08871621465767468| -0.0189063133643019|-0.08871621465767468|    0|\n| 94|0.007432297488510396|0.003946633565674247|0.007432297488510396|0.003946633565674247|0.007432297488510396|0.003946633565674247|    0|\n|110|  0.0334907666040125|  0.0703175032167542|  0.0334907666040125|  0.0703175032167542|  0.0334907666040125|  0.0703175032167542|    0|\n| 57|0.039127744325949065| 0.09049016873590601|0.039127744325949065| 0.09049016873590601|0.039127744325949065| 0.09049016873590601|    0|\n| 32|-0.13783372672389743|  0.0630534416705046|-0.13783372672389743|  0.0630534416705046|-0.13783372672389743|  0.0630534416705046|    0|\n| 43| 0.04362147516153375|-0.04661273772305589| 0.04362147516153375|-0.04661273772305589| 0.04362147516153375|-0.04661273772305589|    0|\n| 84|0.041318959515210835|-0.02405618890046...|0.041318959515210835|-0.02405618890046...|0.041318959515210835|-0.02405618890046...|    0|\n| 31| -0.0213952544564988| -0.1156058071676539| -0.0213952544564988| -0.1156058071676539| -0.0213952544564988| -0.1156058071676539|    0|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a VectorAssembler which consumes the newly created DFT columns and produces a column called \u201cfeatures\u201d.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.feature import VectorAssembler",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "vectorAssembler = VectorAssembler().setInputCols([\"xa\", \"xb\", \"ya\", \"yb\", \"za\", \"zb\", \"class\"]).setOutputCol(\"features\") ###YOUR_CODE_GOES_HERE###",
            "execution_count": 23,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Insatiate a classifier from the SparkML package and assign it to the classifier variable. Make sure to set the \u201cclass\u201d column as target.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.classification import GBTClassifier # Gradient-boosted tree classifier",
            "execution_count": 24,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "classifier = ### YOUR CODE HERE ### Use GBTClassifier or another classifier of your choice",
            "execution_count": 25,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let\u2019s train and evaluate\u2026\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, classifier])",
            "execution_count": 26,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "model = pipeline.fit(df_dft)",
            "execution_count": 27,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "prediction = model.transform(df_dft)",
            "execution_count": 28,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "prediction.show()",
            "execution_count": 29,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n| id|                  xa|                  xb|                  ya|                  yb|                  za|                  zb|class|            features|       rawPrediction|         probability|prediction|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n| 26| 0.03912775214058598|-0.09049016952668232| 0.03912775214058598|-0.09049016952668232| 0.03912775214058598|-0.09049016952668232|    0|[0.03912775214058...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 29|0.006260524476137005|-0.05765058448048809|0.006260524476137005|-0.05765058448048809|0.006260524476137005|-0.05765058448048809|    0|[0.00626052447613...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 65| -0.0686442877106673| 0.06538926077517343| -0.0686442877106673| 0.06538926077517343| -0.0686442877106673| 0.06538926077517343|    0|[-0.0686442877106...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 19| 0.07207851982267682|-0.00555713532424...| 0.07207851982267682|-0.00555713532424...| 0.07207851982267682|-0.00555713532424...|    0|[0.07207851982267...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 54| 0.03806782602909542|-0.15673003795074777| 0.03806782602909542|-0.15673003795074777| 0.03806782602909542|-0.15673003795074777|    0|[0.03806782602909...|[1.32590267922033...|[0.93412217565278...|       0.0|\n|  0| 0.06178937294558884|-0.03961749197816182| 0.06178937294558884|-0.03961749197816182| 0.06178937294558884|-0.03961749197816182|    0|[0.06178937294558...|[1.32590267922033...|[0.93412217565278...|       0.0|\n|112|0.050945537592681445|-0.00299428645504...|0.050945537592681445|-0.00299428645504...|0.050945537592681445|-0.00299428645504...|    0|[0.05094553759268...|[1.32590267922033...|[0.93412217565278...|       0.0|\n|113| 0.06178937118785787| 0.03961749600785146| 0.06178937118785787| 0.03961749600785146| 0.06178937118785787| 0.03961749600785146|    0|[0.06178937118785...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 22|-0.00942353499552...|0.014489276203582657|-0.00942353499552...|0.014489276203582657|-0.00942353499552...|0.014489276203582657|    0|[-0.0094235349955...|[1.32590267922033...|[0.93412217565278...|       0.0|\n|  7|-0.02139526027010...| 0.11560580654216471|-0.02139526027010...| 0.11560580654216471|-0.02139526027010...| 0.11560580654216471|    0|[-0.0213952602701...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 77|-0.07768949082949561|0.039133460895471164|-0.07768949082949561|0.039133460895471164|-0.07768949082949561|0.039133460895471164|    0|[-0.0776894908294...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 34|-0.08799817666162946|0.017746602649508163|-0.08799817666162946|0.017746602649508163|-0.08799817666162946|0.017746602649508163|    0|[-0.0879981766616...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 50| -0.0189063133643019|-0.08871621465767468| -0.0189063133643019|-0.08871621465767468| -0.0189063133643019|-0.08871621465767468|    0|[-0.0189063133643...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 94|0.007432297488510396|0.003946633565674247|0.007432297488510396|0.003946633565674247|0.007432297488510396|0.003946633565674247|    0|[0.00743229748851...|[1.32590267922033...|[0.93412217565278...|       0.0|\n|110|  0.0334907666040125|  0.0703175032167542|  0.0334907666040125|  0.0703175032167542|  0.0334907666040125|  0.0703175032167542|    0|[0.03349076660401...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 57|0.039127744325949065| 0.09049016873590601|0.039127744325949065| 0.09049016873590601|0.039127744325949065| 0.09049016873590601|    0|[0.03912774432594...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 32|-0.13783372672389743|  0.0630534416705046|-0.13783372672389743|  0.0630534416705046|-0.13783372672389743|  0.0630534416705046|    0|[-0.1378337267238...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 43| 0.04362147516153375|-0.04661273772305589| 0.04362147516153375|-0.04661273772305589| 0.04362147516153375|-0.04661273772305589|    0|[0.04362147516153...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 84|0.041318959515210835|-0.02405618890046...|0.041318959515210835|-0.02405618890046...|0.041318959515210835|-0.02405618890046...|    0|[0.04131895951521...|[1.32590267922033...|[0.93412217565278...|       0.0|\n| 31| -0.0213952544564988| -0.1156058071676539| -0.0213952544564988| -0.1156058071676539| -0.0213952544564988| -0.1156058071676539|    0|[-0.0213952544564...|[1.32590267922033...|[0.93412217565278...|       0.0|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nbinEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setPredictionCol(\"prediction\").setLabelCol(\"class\")\n    \nbinEval.evaluate(prediction) ",
            "execution_count": 30,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 30,
                    "data": {
                        "text/plain": "1.0"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "A good result is > 0.8"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}